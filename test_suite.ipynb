{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f2848-abad-43c3-b60e-4ac30357618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.dsl import Output, Metrics, HTML\n",
    "\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['minio', 'numpy', 'tensorflow']\n",
    ")\n",
    "def upload_test_data() -> NamedTuple('Outputs', [('datapoints_training', float),('datapoints_test', float),('dataset_version', str)]):\n",
    "    \"\"\"\n",
    "    Function to upload test dataset and load it to minio bucket\n",
    "    \"\"\"\n",
    "    print(\"uploading test data\")\n",
    "    from tensorflow import keras\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"10.244.0.40:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    # Load MNIST dataset directly from Keras\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # save to numpy file, store in Minio (in your original context, you would store in Minio here)\n",
    "    np.save(\"/tmp/x_train.npy\", x_train)\n",
    "    np.save(\"/tmp/y_train.npy\", y_train)\n",
    "    np.save(\"/tmp/x_test.npy\", x_test)\n",
    "    np.save(\"/tmp/y_test.npy\", y_test)\n",
    "    \n",
    "    try:\n",
    "        minio_client.fput_object(minio_bucket, \"x_train.npy\", \"/tmp/x_train.npy\")\n",
    "        minio_client.fput_object(minio_bucket, \"y_train.npy\", \"/tmp/y_train.npy\")\n",
    "        minio_client.fput_object(minio_bucket, \"x_test.npy\", \"/tmp/x_test.npy\")\n",
    "        minio_client.fput_object(minio_bucket, \"y_test.npy\", \"/tmp/y_test.npy\")\n",
    "    except Exception as e:\n",
    "        print(f\"Datasets already exist: {e}\")\n",
    "    \n",
    "    dataset_version = \"1.0\"\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    outputs_tuple = namedtuple('Outputs', ['datapoints_training', 'datapoints_test', 'dataset_version'])\n",
    "    return outputs_tuple(float(x_train.shape[0]), float(x_test.shape[0]), dataset_version)\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['minio', 'numpy', 'tensorflow']\n",
    ")\n",
    "def get_test_data() -> NamedTuple('Outputs', [('datapoints_training', float),('datapoints_test', float),('dataset_version', str)]):\n",
    "    \"\"\"\n",
    "    Function to get test dataset and load it to minio bucket\n",
    "    \"\"\"\n",
    "    print(\"getting test data\")\n",
    "    from tensorflow import keras\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"10.244.0.40:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    files = [\"x_train.npy\", \"y_train.npy\", \"x_test.npy\", \"y_test.npy\"]\n",
    "    for file in files:\n",
    "        minio_client.fget_object(minio_bucket, file, f\"/tmp/{file}\")\n",
    "\n",
    "    # Cargar datos desde los archivos locales\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "    y_train = np.load(\"/tmp/y_train.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "    y_test = np.load(\"/tmp/y_test.npy\")\n",
    "    \n",
    "    dataset_version = \"1.0\"\n",
    "    \n",
    "    print(f\"x_train shape: {x_train.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "\n",
    "    print(f\"x_test shape: {x_test.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    outputs_tuple = namedtuple('Outputs', ['datapoints_training', 'datapoints_test', 'dataset_version'])\n",
    "    return outputs_tuple(float(x_train.shape[0]), float(x_test.shape[0]), dataset_version)\n",
    "\n",
    "\n",
    "@dsl.component(\n",
    "    base_image='python:3.10',\n",
    "    packages_to_install=['minio', 'numpy']\n",
    ")\n",
    "def test_models(ui_metadata: Output[HTML]):\n",
    "    \"\"\"\n",
    "    Use the test data to measure and check the functionality of the models\n",
    "    \"\"\"\n",
    "    print(\"testing models\")\n",
    "    \n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import json\n",
    "\n",
    "    minio_client = Minio(\n",
    "        \"10.244.0.40:9000\",\n",
    "        access_key=\"minio\",\n",
    "        secret_key=\"minio123\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"mlpipeline\"\n",
    "    \n",
    "    # load data from minio\n",
    "    minio_client.fget_object(minio_bucket,\"x_train.npy\",\"/tmp/x_train.npy\")\n",
    "    x_train = np.load(\"/tmp/x_train.npy\")\n",
    "    \n",
    "    minio_client.fget_object(minio_bucket,\"x_test.npy\",\"/tmp/x_test.npy\")\n",
    "    x_test = np.load(\"/tmp/x_test.npy\")\n",
    "    \n",
    "    # reshaping the data\n",
    "    # reshaping pixels in a 28x28px image with greyscale, canal = 1. This is needed for the Keras API\n",
    "    x_train = x_train.reshape(-1,28,28,1)\n",
    "    x_test = x_test.reshape(-1,28,28,1)\n",
    "\n",
    "    # normalizing the data\n",
    "    # each pixel has a value between 0-255. Here we divide by 255, to get values from 0-1\n",
    "    x_train = x_train / 255\n",
    "    x_test = x_test / 255\n",
    "    \n",
    "    # save data from minio\n",
    "    np.save(\"/tmp/x_train.npy\",x_train)\n",
    "    minio_client.fput_object(minio_bucket,\"x_train.npy\",\"/tmp/x_train.npy\")\n",
    "    \n",
    "    np.save(\"/tmp/x_test.npy\",x_test)\n",
    "    minio_client.fput_object(minio_bucket,\"x_test.npy\",\"/tmp/x_test.npy\")\n",
    "\n",
    "    metadata_dict = {}\n",
    "\n",
    "    with open(ui_metadata.path, \"w\") as f:\n",
    "        json.dump(metadata_dict, f)\n",
    "        \n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='test_digits-recognizer-pipeline',\n",
    "    description='Test suite for detect digits'\n",
    ")\n",
    "def output_test():\n",
    "\n",
    "    comp_upload_test_data = upload_test_data()\n",
    "    comp_get_test_data = get_test_data()\n",
    "    comp_test_models = test_models()\n",
    "\n",
    "    step1 = comp_upload_test_data\n",
    "    \n",
    "    step2 = comp_get_test_data\n",
    "    step2.after(step1)\n",
    "    \n",
    "    step3 = comp_test_models\n",
    "    step3.after(step2)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = kfp.Client()\n",
    "\n",
    "    run_directly = 1\n",
    "    \n",
    "    if (run_directly == 1):\n",
    "        client.create_run_from_pipeline_func(output_test,experiment_name=\"test_suite\",run_name=\"test-digits-recognizer-pipeline\")\n",
    "    else:\n",
    "        kfp.compiler.Compiler().compile(pipeline_func=output_test,package_path='output_test_sequential.yaml')\n",
    "        client.upload_pipeline_version(pipeline_package_path='output_test.yaml',pipeline_version_name=\"0.4\",pipeline_name='test-digits-recognizer-pipeline',description=\"just for testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
